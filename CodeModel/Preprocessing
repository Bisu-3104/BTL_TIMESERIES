image_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                         std=[0.229, 0.224, 0.225])
])
resnet = models.resnet50(pretrained=True)

modules = list(resnet.children())[:-2] 
cnn_backbone = nn.Sequential(*modules, nn.AdaptiveAvgPool2d((1, 1))) 

feature_extractor = nn.Sequential(
    cnn_backbone,
    nn.Flatten(),              
    nn.Linear(2048, 512)     
).to(device)

def feature_extraction(filenames, feature_extractor):
    feature_extractor.eval()
    image_features = []

    for img_path in tqdm(filenames):
        img = Image.open(img_path).convert('RGB')
        img_tensor = image_transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            feat = feature_extractor(img_tensor)  # (1, 512)
            feat = feat.squeeze(0).cpu()          # (512,)
            image_features.append(feat)

    return image_features

image_features = feature_extraction(df['filename'], feature_extractor)
len(image_features)
